# Variables to select
scaled_blm_predict <- c("log_Temp_C_std", "pH_std", "log_DOC_M_std",
"log_DIC_mM_std", "log_Cl_uM_std", "log_Ca_uM_std",
"log_Mg_uM_std", "log_SO4_uM_std", "log_Na_uM_std",
"log_K_uM_std")
# Subset of dat
scaled_blm_predict <- dat %>%
dplyr::select(all_of(vars_to_select))
# Spearman correlation matrix on standardized variables
cor_matrix <- cor(scaled_blm_predict, method="spearman")
# Heatmap
library(corrplot)
corrplot(cor_matrix,
method = "color",
tl.cex = 0.7,
tl.col = "black",
addCoef.col = "black",
number.cex = 0.6)
pca_result <- prcomp(scaled_blm_predict, center = TRUE, scale. = TRUE)
pca_result
pca_summary <- summary(pca_result)
pca_summary
library(factoextra)
library(ggplot2)
library(dplyr)
# Make sure Development is a factor with correct levels
dat$Development <- factor(dat$Development, levels = c("Low intensity", "Medium intensity", "High intensity"))
# Assign colors for Typology
typology_colors <- c(
"Main Stem" = "#999999",
"Perennial Developed Tribs" = "#D55E00",
"Flowing Tribs"   = "#56B4E9",
"Pooled Tribs" = "#E69F00"
)
# Assign colors for Development ellipses
development_colors <- c(
"Low intensity" = "yellow",
"Medium intensity" = "orange",
"High intensity" = "red"
)
# Base PCA biplot (points colored by Typology)
pca_all_dat <- fviz_pca_biplot(pca_result,
geom.ind = "point",
col.ind = dat$Typology,  #color points by typology
shape.ind = 16,
col.var = "black",
repel = TRUE,
label = "var") +
scale_color_manual(values = typology_colors) +       # point colors
scale_shape_manual(values = rep(16, length(unique(dat$Typology)))) +
labs(title = "PCA on BLM Predictors: Points by Cluster, Ellipses by Development") +
theme_minimal() +
coord_cartesian(xlim = c(-12, 12), ylim = c(-6, 6))
# Add ellipses for Development groups
pca_all_dat <- pca_all_dat +
stat_ellipse(
data = cbind(pca_result$ind$coord, Development = dat$Development),
aes(x = Dim.1, y = Dim.2, fill = Development),
geom = "polygon",
alpha = 0.2,
color = NA
) +
scale_fill_manual(values = development_colors)  # ellipse fill colors
# View
pca_all_dat
pca_all_dat <- pca_all_dat +
stat_ellipse(
data = data.frame(pca_result$ind$coord, Development = dat$Development),
aes(x = Dim.1, y = Dim.2, fill = Development),
geom = "polygon",
alpha = 0.2,
color = NA
) +
scale_fill_manual(values = development_colors)  # ellipse fill colors
library(dplyr)
f_tribs <- dat %>% filter(Typology == "Flowing Tribs")
# check
head(f_tribs)
# Isolate scaled BLM predictors
scaled_blm_predict <-
f_tribs %>%
dplyr::select(
log_Temp_C_std, pH_std, log_DOC_M_std, log_SO4_uM_std,
log_DIC_mM_std, log_Cl_uM_std, log_Ca_uM_std, log_Mg_uM_std,
log_SO4_uM_std, log_Na_uM_std, log_K_uM_std)
pca_result <- prcomp(scaled_blm_predict, center = TRUE, scale. = TRUE)
pca_result
pca_summary <- summary(pca_result)
pca_summary
library(factoextra)
library(ggplot2)
# Ensure Development is a factor with levels
pd_tribs$Development <- factor(f_tribs$Development,
levels = c("Low intensity",
"Medium intensity",
"High intensity"))
library(factoextra)
library(ggplot2)
# Ensure Development is a factor with levels
f_tribs$Development <- factor(f_tribs$Development,
levels = c("Low intensity",
"Medium intensity",
"High intensity"))
# Assign color-blind friendly colors to level of development
development_colors <- c(
"Low intensity" = "yellow3",
"Medium intensity" = "orange2",
"High intensity" = "red3"
)
#
pca_f_tribs_development <- fviz_pca_biplot(pca_result,
geom.ind = "point",
col.ind = pd_tribs$Development,  # color points by Development
shape.ind = 16,              # all circles
addEllipses = TRUE,
legend.title = "Level of Development",
col.var = "black",
repel = TRUE,
label = "var"                # label the variables
) +
scale_color_manual(values = development_colors) +
scale_fill_manual(values = development_colors) +
scale_shape_manual(values = rep(16, length(unique(pd_tribs$Development)))) +
labs(title = "PCA on BLM Predictors: Sites Grouped by Development") +
coord_cartesian(xlim = c(-10, 10), ylim = c(-7, 4)) +
theme_minimal()
library(factoextra)
library(ggplot2)
# Ensure Development is a factor with levels
f_tribs$Development <- factor(f_tribs$Development,
levels = c("Low intensity",
"Medium intensity",
"High intensity"))
# Assign color-blind friendly colors to level of development
development_colors <- c(
"Low intensity" = "yellow3",
"Medium intensity" = "orange2",
"High intensity" = "red3"
)
#
pca_f_tribs_development <- fviz_pca_biplot(pca_result,
geom.ind = "point",
col.ind = f_tribs$Development,  # color points by Development
shape.ind = 16,              # all circles
addEllipses = TRUE,
legend.title = "Level of Development",
col.var = "black",
repel = TRUE,
label = "var"                # label the variables
) +
scale_color_manual(values = development_colors) +
scale_fill_manual(values = development_colors) +
scale_shape_manual(values = rep(16, length(unique(pd_tribs$Development)))) +
labs(title = "PCA on BLM Predictors: Sites Grouped by Development") +
coord_cartesian(xlim = c(-10, 10), ylim = c(-7, 4)) +
theme_minimal()
# View
pca_f_tribs_development
library(factoextra)
library(ggplot2)
# Ensure Drainage area is a factor with levels
f_tribs$Drainage_area <- factor(f_tribs$Drainage_area,
levels = c("<1 km2", "1-10 km2", ">10 km2"))
# Assign color-blind friendly colors to level of development
drainage_area_colors <- c(
"<1 km2" = "lightgray",
"1-10 km2" = "darkgray",
">10 km2" = "black"
)
#
pca_f_tribs_development <- fviz_pca_biplot(pca_result,
geom.ind = "point",
col.ind = f_tribs$Drainage_area,  # color points by Development
shape.ind = 16,              # all circles
addEllipses = TRUE,
legend.title = "Drainage Area",
col.var = "black",
repel = TRUE,
label = "var"                # label the variables
) +
scale_color_manual(values = drainage_area_colors) +
scale_fill_manual(values = drainage_area_colors) +
scale_shape_manual(values = rep(16, length(unique(f_tribs$Drainage_area)))) +
labs(title = "PCA on BLM Predictors: Sites Grouped by Drainage Area") +
coord_cartesian(xlim = c(-10, 10), ylim = c(-7, 4)) +
theme_minimal()
# View
pca_f_tribs_development
library(factoextra)
library(ggplot2)
# Ensure Drainage area is a factor with levels
f_tribs$Distance_from_EFPC <- as.factor(f_tribs$Distance_from_EFPC)
f_tribs$Distance_from_EFPC <- factor(f_tribs$Distance_from_EFPC,
levels = c("<1 km", ">1 km"))
# Assign color-blind friendly colors to level of development
dist_from_main_stem_colors <- c(
"<1 km" = "chartreuse2",
">1 km" = "forestgreen"
)
#
pca_f_tribs_dist <- fviz_pca_biplot(pca_result,
geom.ind = "point",
col.ind = f_tribs$Distance_from_EFPC,
shape.ind = 16,
addEllipses = TRUE,
legend.title = "Distance from Main Stem",
col.var = "black",
repel = TRUE,
label = "var"                #
) +
scale_color_manual(values = dist_from_main_stem_colors) +
scale_fill_manual(values = dist_from_main_stem_colors) +
scale_shape_manual(values = rep(16, length(unique(f_tribs$Distance_from_EFPC)))) +
labs(title = "PCA on BLM Predictors: Sites Grouped by Distance from Main Stem") +
coord_cartesian(xlim = c(-10, 10), ylim = c(-7, 4)) +
theme_minimal()
# View
pca_f_tribs_dist
setwd("C:/Users/q4q/repos/STAT_563_Project_2")
# Load necessary library
library(stats)
# Step 1: Generate random numbers from a logistic distribution
set.seed(123)  # For reproducibility
n <- 200
true_mu <- 0
true_s <- 1
# Logistic random variables
x <- rlogis(n, location = true_mu, scale = true_s)
hist(x)
# Load necessary library
library(stats)
# Step 1: Generate random numbers from a logistic distribution
set.seed(123)  # For reproducibility
n <- 200
true_mu <- 0
true_s <- 1
# Logistic random variables
x <- rlogis(n, location = true_mu, scale = true_s)
# View
hist(x)
# Estimate mean and scale
mu_hat <- mean(x)
s_hat  <- sd(x) * sqrt(3)/pi   # approximate logistic scale from SD
# Variance of the sample mean using logistic formula
var_mu <- (pi^2 * s_hat^2) / (3 * n)  # Var(mean) = Var(X)/n
se_mu  <- sqrt(var_mu)
# 95% Wald CI
z <- qnorm(0.975)
ci_wald <- mu_hat + c(-1,1) * z * se_mu
ci_wald
set.seed(123)
B <- 1000  # number of bootstrap samples
mu_boot <- replicate(B, {
xb <- sample(x, replace = TRUE)
mean(xb)
})
# 95% percentile bootstrap CI
ci_boot <- quantile(mu_boot, probs = c(0.025, 0.975))
ci_boot
# libraries
library(ggplot2)
library(dplyr)
# Bootstrap CIs for the mean under a Logistic(mu, s) population
# Compare Normal (Wald) CI vs Percentile Bootstrap CI
set.seed(0)
# --- Population (for simulation) ---
mu <- 0
s <- 1                  # Logistic location & scale
n <- 80                 # sample size
# Simulate logistic via inverse-CDF (same as MATLAB)
u <- runif(n)
X <- mu + s * log(u / (1 - u))
# Alternatively, could use: X <- rlogis(n, location = mu, scale = s)
# --- Point estimate and asymptotic (normal/Wald) CI ---
xbar <- mean(X)
s_hat <- sqrt(var(X) * 3 / pi^2)   # plug-in estimator for logistic scale
z <- qnorm(0.975)
ci_wald <- c(
xbar - z * sqrt((pi^2 * s_hat^2) / (3 * n)),
xbar + z * sqrt((pi^2 * s_hat^2) / (3 * n))
)
# --- Bootstrap percentile CI ---
B <- 2000
boot_means <- numeric(B)
for (b in 1:B) {
Xb <- sample(X, size = n, replace = TRUE)
boot_means[b] <- mean(Xb)
}
ci_boot <- quantile(boot_means, probs = c(0.025, 0.975))
# --- Display results ---
cat(sprintf("Sample mean      = %.4f\n", xbar))
cat(sprintf("Normal (Wald) CI = [%.4f, %.4f]\n", ci_wald[1], ci_wald[2]))
cat(sprintf("Percentile CI    = [%.4f, %.4f]\n", ci_boot[1], ci_boot[2]))
# --- Compare widths ---
width_wald <- diff(ci_wald)
width_boot <- diff(ci_boot)
cat(sprintf("Wald width       = %.4f\n", width_wald))
cat(sprintf("Bootstrap width  = %.4f\n", width_boot))
# --- Plot ---
hist(boot_means, breaks = 40, freq = FALSE,
main = "Bootstrap distribution of the sample mean (Logistic population)",
xlab = "Mean", col = "lightgray", border = "white")
# Add density curve
lines(density(boot_means), col = "black", lwd = 2)
# Add reference lines
abline(v = xbar, col = "black", lwd = 2)                 # sample mean
abline(v = ci_boot, col = "red", lty = 2, lwd = 2)       # bootstrap CI
abline(v = ci_wald, col = "blue", lty = 3, lwd = 2)      # normal (Wald) CI
legend("topright",
legend = c("Sample mean", "Bootstrap 95% CI", "Wald 95% CI"),
col = c("black", "red", "blue"),
lty = c(1, 2, 3),
lwd = 2)
## ------------------------------------------------------------
## BOOTSTRAP_CORRELATION_MATRIX_SLICE.R
##
## Bootstrap the full d×d correlation matrix from a dataset,
## then slice-sample the marginal density of a chosen correlation r_{j,k}.
## ------------------------------------------------------------
# Load packages
library(MASS)       # for mvrnorm
library(stats)      # for cor, quantile, density
library(ks)         # for optional kde if needed
set.seed(0)
# --- Data generation (replace with your real data) ---
n <- 200
d <- 5
rho <- 0.7
Sigma <- toeplitz(rho^(0:(d-1)))   # AR(1)-like correlation
X <- MASS::mvrnorm(n = n, mu = rep(0, d), Sigma = Sigma)
# --- Bootstrap correlation matrix ---
B <- 1500
p <- d * (d - 1) / 2
Rvec <- matrix(NA, nrow = B, ncol = p)
inds <- which(upper.tri(diag(d), diag = FALSE))  # indices of upper triangle
for (b in 1:B) {
idx <- sample(1:n, n, replace = TRUE)
Xb <- X[idx, ]
Rb <- cor(Xb)
Rvec[b, ] <- Rb[inds]
}
# --- Choose a pair (j, k) to study ---
j <- 1
k <- 3
colmap <- matrix(0, nrow = d, ncol = d)
colmap[upper.tri(colmap)] <- 1:p
col <- colmap[j, k]
r_boot <- Rvec[, col]
# --- Compare to Fisher-z interval ---
z <- 0.5 * log((1 + r_boot) / (1 - r_boot))
z_mean <- mean(z)
z_se <- 1 / sqrt(n - 3)
z_ci <- c(z_mean - 1.96 * z_se, z_mean + 1.96 * z_se)
ci_fisher <- (exp(2 * z_ci) - 1) / (exp(2 * z_ci) + 1)
# --- KDE for r in (-1, 1) ---
grid_r <- seq(-0.999, 0.999, length.out = 1000)
dens <- density(r_boot, from = -0.999, to = 0.999, n = 1000)
pdf_fun <- approxfun(dens$x, dens$y, rule = 2)  # interpolate PDF
# --- Define 1D slice sampling function ---
slice1d <- function(logpdf, x0, w, m, nsamp, bounds = c(-1, 1)) {
samples <- numeric(nsamp)
x <- x0
for (i in 1:nsamp) {
y <- logpdf(x) - rexp(1)  # sample vertical level
# step out
L <- x - runif(1) * w
R <- L + w
J <- floor(runif(1) * m)
K <- (m - 1) - J
while (J > 0 && L > bounds[1] && logpdf(L) > y) {
L <- L - w; J <- J - 1
}
while (K > 0 && R < bounds[2] && logpdf(R) > y) {
R <- R + w; K <- K - 1
}
# shrinkage
repeat {
x_new <- runif(1, L, R)
if (x_new < bounds[1] || x_new > bounds[2]) next
if (logpdf(x_new) >= y) {
x <- x_new
break
} else {
if (x_new < x) L <- x_new else R <- x_new
}
}
samples[i] <- x
}
return(samples)
}
# --- Slice sampling over r in (-1, 1) ---
Ns <- 5000
burn <- 1000
r0 <- median(r_boot)
logpdf <- function(r) log(pmax(pdf_fun(r), .Machine$double.xmin))
r_samples <- slice1d(logpdf, r0, w = 0.05, m = 50, nsamp = Ns + burn, bounds = c(-0.999, 0.999))
r_slice <- r_samples[(burn + 1):(Ns + burn)]
# --- Intervals ---
ci_boot <- quantile(r_boot, c(0.025, 0.975))
ci_slice <- quantile(r_slice, c(0.025, 0.975))
cat(sprintf("Correlation r_{%d,%d}\n", j, k))
cat(sprintf("Bootstrap percentile CI : [%.3f, %.3f]\n", ci_boot[1], ci_boot[2]))
cat(sprintf("Fisher-z CI (analytic)  : [%.3f, %.3f]\n", ci_fisher[1], ci_fisher[2]))
cat(sprintf("Slice-sampled CI        : [%.3f, %.3f]\n", ci_slice[1], ci_slice[2]))
# --- Plots ---
par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))
# Left: Bootstrap histogram + CIs
hist(r_boot, breaks = 40, freq = FALSE, col = "lightgray",
main = sprintf("Bootstrap dist. of r_{%d,%d}", j, k),
xlab =
## ------------------------------------------------------------
## BOOTSTRAP_CORRELATION_MATRIX_SLICE.R
##
## Bootstrap the full d×d correlation matrix from a dataset,
## then slice-sample the marginal density of a chosen correlation r_{j,k}.
## ------------------------------------------------------------
# Load packages
library(MASS)       # for mvrnorm
library(stats)      # for cor, quantile, density
library(ks)         # for optional kde if needed
set.seed(0)
# --- Data generation (replace with your real data) ---
n <- 200
d <- 5
rho <- 0.7
Sigma <- toeplitz(rho^(0:(d-1)))   # AR(1)-like correlation
X <- MASS::mvrnorm(n = n, mu = rep(0, d), Sigma = Sigma)
# --- Bootstrap correlation matrix ---
B <- 1500
p <- d * (d - 1) / 2
Rvec <- matrix(NA, nrow = B, ncol = p)
inds <- which(upper.tri(diag(d), diag = FALSE))  # indices of upper triangle
for (b in 1:B) {
idx <- sample(1:n, n, replace = TRUE)
Xb <- X[idx, ]
Rb <- cor(Xb)
Rvec[b, ] <- Rb[inds]
}
# --- Choose a pair (j, k) to study ---
j <- 1
k <- 3
colmap <- matrix(0, nrow = d, ncol = d)
colmap[upper.tri(colmap)] <- 1:p
col <- colmap[j, k]
r_boot <- Rvec[, col]
# --- Compare to Fisher-z interval ---
z <- 0.5 * log((1 + r_boot) / (1 - r_boot))
z_mean <- mean(z)
z_se <- 1 / sqrt(n - 3)
z_ci <- c(z_mean - 1.96 * z_se, z_mean + 1.96 * z_se)
ci_fisher <- (exp(2 * z_ci) - 1) / (exp(2 * z_ci) + 1)
# --- KDE for r in (-1, 1) ---
grid_r <- seq(-0.999, 0.999, length.out = 1000)
dens <- density(r_boot, from = -0.999, to = 0.999, n = 1000)
pdf_fun <- approxfun(dens$x, dens$y, rule = 2)  # interpolate PDF
# --- Define 1D slice sampling function ---
slice1d <- function(logpdf, x0, w, m, nsamp, bounds = c(-1, 1)) {
samples <- numeric(nsamp)
x <- x0
for (i in 1:nsamp) {
y <- logpdf(x) - rexp(1)  # sample vertical level
# step out
L <- x - runif(1) * w
R <- L + w
J <- floor(runif(1) * m)
K <- (m - 1) - J
while (J > 0 && L > bounds[1] && logpdf(L) > y) {
L <- L - w; J <- J - 1
}
while (K > 0 && R < bounds[2] && logpdf(R) > y) {
R <- R + w; K <- K - 1
}
# shrinkage
repeat {
x_new <- runif(1, L, R)
if (x_new < bounds[1] || x_new > bounds[2]) next
if (logpdf(x_new) >= y) {
x <- x_new
break
} else {
if (x_new < x) L <- x_new else R <- x_new
}
}
samples[i] <- x
}
return(samples)
}
# --- Slice sampling over r in (-1, 1) ---
Ns <- 5000
burn <- 1000
r0 <- median(r_boot)
logpdf <- function(r) log(pmax(pdf_fun(r), .Machine$double.xmin))
r_samples <- slice1d(logpdf, r0, w = 0.05, m = 50, nsamp = Ns + burn, bounds = c(-0.999, 0.999))
r_slice <- r_samples[(burn + 1):(Ns + burn)]
# --- Intervals ---
ci_boot <- quantile(r_boot, c(0.025, 0.975))
ci_slice <- quantile(r_slice, c(0.025, 0.975))
cat(sprintf("Correlation r_{%d,%d}\n", j, k))
cat(sprintf("Bootstrap percentile CI : [%.3f, %.3f]\n", ci_boot[1], ci_boot[2]))
cat(sprintf("Fisher-z CI (analytic)  : [%.3f, %.3f]\n", ci_fisher[1], ci_fisher[2]))
cat(sprintf("Slice-sampled CI        : [%.3f, %.3f]\n", ci_slice[1], ci_slice[2]))
# --- Plots ---
par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))
# Left: Bootstrap histogram + CIs
hist(r_boot, breaks = 40, freq = FALSE, col = "lightgray",
main = sprintf("Bootstrap dist. of r_{%d,%d}", j, k),
xlab = sprintf("r_{%d,%d}", j, k))
lines(dens, lwd = 2)
abline(v = ci_boot, col = "red", lty = 2, lwd = 2)
abline(v = ci_fisher, col = "blue", lty = 3, lwd = 2)
legend("topleft", legend = c("Bootstrap CI", "Fisher-z CI"),
col = c("red", "blue"), lty = c(2, 3), lwd = 2, bty = "n")
